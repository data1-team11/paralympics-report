[
  {
    "objectID": "transport.html",
    "href": "transport.html",
    "title": "Transport",
    "section": "",
    "text": "For our swimming route we chose a path through the following coordinates.\n\n52.370631, 4.912138\n52.366824, 4.906239\n52.365795, 4.908870\n52.364477, 4.901910\n52.362811, 4.902780\n52.363131, 4.904473\n52.362023, 4.905010\n52.363891, 4.914505\n52.363334, 4.916339\n52.365548, 4.921682\n52.366120, 4.921192\n52.367123, 4.918531\n52.368649, 4.919936\n52.367450, 4.924110\n52.371675, 4.912920\n52.372894, 4.913767\n52.373418, 4.915827\n\n(52.373418, 4.915827)\n\n\nCreating the lists for our dataframe of coordinates\n\nlongitude = ['52.370631', '52.366824', '52.365795', '52.364477', '52.362811',\n             '52.363131', '52.362023', '52.363891', '52.363334', '52.365548',\n             '52.366120', '52.367123', '52.368649', '52.367450', '52.371675',\n             '52.372894', '52.373418']\nlatitude = ['4.912138', '4.906239', '4.908870', '4.901910', '4.902780',\n            '4.904473', '4.905010', '4.914505', '4.916339', '4.921682',\n            '4.921192', '4.918531', '4.919936', '4.924110', '4.912920',\n            '4.913767', '4.915827']\n#print(len(latitude))\n#print(coordinates)\n\n17\n\n\nBelow we calculate the center of the nodes of the swimming route.\n\nimport pandas as pd\nimport plotly as pl\nimport osmnx as ox\nimport pickle\n\ndf = pd.DataFrame(longitude)\n\ncolumns = ['longitude']\ndf.columns = columns\n\ndf.insert(1, 'latitude', latitude)\n# print(df)\n\nlongnum = pd.to_numeric(longitude)\nlatnum = pd.to_numeric(latitude)\n\ndf.insert(0, 'longnum', longnum)\ndf.insert(1, 'latnum', latnum)\nprint(df)\n\navg_lon = (df.longnum.sum() / len(longnum))\navg_lat = (df.latnum.sum() / len(latnum))\n\nstart_swim = (df.longnum[0], df.latnum[0])\nfinish_swim = (df.longnum[16], df.latnum[16])\n\n# center of the nodes of the swimming route\ncenter = (avg_lon, avg_lat)\n\nprint(center)\n# print(start_swim)\n# print(df.longnum[16])\n\n      longnum    latnum  longitude  latitude\n0   52.370631  4.912138  52.370631  4.912138\n1   52.366824  4.906239  52.366824  4.906239\n2   52.365795  4.908870  52.365795  4.908870\n3   52.364477  4.901910  52.364477  4.901910\n4   52.362811  4.902780  52.362811  4.902780\n5   52.363131  4.904473  52.363131  4.904473\n6   52.362023  4.905010  52.362023  4.905010\n7   52.363891  4.914505  52.363891  4.914505\n8   52.363334  4.916339  52.363334  4.916339\n9   52.365548  4.921682  52.365548  4.921682\n10  52.366120  4.921192  52.366120  4.921192\n11  52.367123  4.918531  52.367123  4.918531\n12  52.368649  4.919936  52.368649  4.919936\n13  52.367450  4.924110  52.367450  4.924110\n14  52.371675  4.912920  52.371675  4.912920\n15  52.372894  4.913767  52.372894  4.913767\n16  52.373418  4.915827  52.373418  4.915827\n(52.36681141176471, 4.9129546470588235)\n\n\n\nimport osmnx as ox\nimport pickle\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport gpxpy\nimport gpxpy.gpx\nimport codecs\nimport requests\nimport geopandas as gpd\nimport geopy.distance as geo\nimport json\nimport plotly as py\nfrom shapely.geometry import Point, Polygon\nimport plotly.express as px\n\n\ncenter = (avg_lon, avg_lat)\n\ntags = {'highway':['bus_stop'], 'public_transport':['stop_area', 'stop_position']} \ntags_10min = {'amenity':['cafe', 'restaurant', 'bar', 'pub']}\ntags1 = {'building': True}  # 'waterway': True\n\ngdf = ox.features.features_from_point(center, tags = tags, dist = 1300)  # = {'public_transport':['stop_area','stop_position', 'platform']}, dist = 1000)\ngdf.head()\ngdf.info()\n\ngdf1 = ox.features.features_from_point(center, tags = tags1, dist = 50)\ngdf1.head()\ngdf1.info()\n\ngdf2 = ox.features.features_from_point(finish_swim, tags = tags_10min, dist = 50)\ngdf2.head()\ngdf2.info()\n\n\nlink = \"https://maps.amsterdam.nl/open_geodata/geojson_lnglat.php?KAARTLAAG=TRAMMETRO_PUNTEN_2022&THEMA=trammetro\"\nlink_answer = requests.get(link)\ngdf_link_answer = gpd.read_file(link_answer.text)\n\ngdf_link_answer['distance'] = gdf_link_answer['geometry'].apply(lambda stop: geo.great_circle(finish_swim, (stop.y, stop.x)).meters)\n\n\nstops = gdf_link_answer.nsmallest(5, 'distance')\nprint(stops)\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 201 entries, ('node', 46350382) to ('node', 10208418533)\nData columns (total 34 columns):\n #   Column                  Non-Null Count  Dtype   \n---  ------                  --------------  -----   \n 0   name                    201 non-null    object  \n 1   public_transport        201 non-null    object  \n 2   railway                 86 non-null     object  \n 3   tram                    75 non-null     object  \n 4   wheelchair              74 non-null     object  \n 5   wikidata                71 non-null     object  \n 6   geometry                201 non-null    geometry\n 7   bus                     117 non-null    object  \n 8   source                  1 non-null      object  \n 9   note                    3 non-null      object  \n 10  ref:IFOPT               40 non-null     object  \n 11  level                   1 non-null      object  \n 12  toilets:wheelchair      3 non-null      object  \n 13  network                 8 non-null      object  \n 14  station                 6 non-null      object  \n 15  subway                  8 non-null      object  \n 16  zone                    25 non-null     object  \n 17  name:de                 26 non-null     object  \n 18  ref                     8 non-null      object  \n 19  train                   5 non-null      object  \n 20  name:es                 1 non-null      object  \n 21  name:nl                 2 non-null      object  \n 22  old_name                6 non-null      object  \n 23  bench                   42 non-null     object  \n 24  bin                     34 non-null     object  \n 25  highway                 59 non-null     object  \n 26  lit                     23 non-null     object  \n 27  operator                7 non-null      object  \n 28  shelter                 49 non-null     object  \n 29  tactile_paving          27 non-null     object  \n 30  covered                 1 non-null      object  \n 31  wheelchair:description  1 non-null      object  \n 32  check_date:shelter      2 non-null      object  \n 33  website                 1 non-null      object  \ndtypes: geometry(1), object(33)\nmemory usage: 63.9+ KB\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nMultiIndex: 18 entries, ('way', 26525263) to ('way', 860196314)\nData columns (total 15 columns):\n #   Column             Non-Null Count  Dtype   \n---  ------             --------------  -----   \n 0   geometry           18 non-null     geometry\n 1   nodes              18 non-null     object  \n 2   building           18 non-null     object  \n 3   name               4 non-null      object  \n 4   ref:bag            15 non-null     object  \n 5   shop               1 non-null      object  \n 6   source             15 non-null     object  \n 7   source:date        15 non-null     object  \n 8   start_date         15 non-null     object  \n 9   wikidata           2 non-null      object  \n 10  wikimedia_commons  2 non-null      object  \n 11  height             1 non-null      object  \n 12  name:de            2 non-null      object  \n 13  name:nl            1 non-null      object  \n 14  wikipedia:nl       1 non-null      object  \ndtypes: geometry(1), object(14)\nmemory usage: 3.1+ KB\n                      Naam Modaliteit Lijn Lijn_select  RADIUS  \\\n121   Muziekgebouw Bimhuis       Tram   26          26       5   \n122     Kattenburgerstraat       Tram   26          26       5   \n76                   Artis       Tram   14          14       5   \n34   Eerste Coehoornstraat       Tram    7           7       5   \n223     Plantage Lepellaan       Tram   14          14       5   \n\n                         Label                  geometry    distance  \n121  26 - Muziekgebouw Bimhuis  POINT (4.91302 52.37725)  466.432472  \n122    26 - Kattenburgerstraat  POINT (4.92158 52.37612)  492.763524  \n76                  14 - Artis  POINT (4.91117 52.36663)  818.541501  \n34   7 - Eerste Coehoornstraat  POINT (4.92646 52.36827)  921.032540  \n223    14 - Plantage Lepellaan  POINT (4.91548 52.36513)  921.818880  \n\n\n\ncityswim = ox.graph.graph_from_point(center, dist=1300,\n                                     network_type='all', dist_type='network')\n\nnorth = float(avg_lat)+.1\nsouth = float(avg_lat)-.1\nwest = float(avg_lon)-.1\neast = float(avg_lon)+.1\n\nedges_map = Polygon([(west, north), (east, north), (east, south),\n                     (west, south), (west, north)])\nwater = ox.geometries.geometries_from_bbox(north, south, east,\n                                           west, tags={'natural' : 'water'})\nwater = water.clip(edges_map)\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.set_aspect('equal')\nax.set_facecolor('white')\n\nox.plot_graph(cityswim, edge_color='grey',\n                        node_size=0,\n                        show=False, close=False, ax=ax,)\n\ngdf.plot(ax=ax, markersize=20, color=\"red\")  # closest bus stops\nstops.plot(ax=ax, markersize=20, color=\"orange\")\ngdf1.plot(ax=ax, color=\"purple\")  # We determine a 50m radius for the close\n# buildings in order to ssign the HQ of the race.\ngdf2.plot(ax=ax, color = \"dark green\")\nwater.plot(ax=ax, color=\"lightblue\")\n\nplt.savefig(\"publictransport.png\")\n\n\n\n\nWe used the available data to find the capacity of public transport. We have 5 tram stops wihtin 1 km. The tram passes about 5-10 times and hour so averaging 7.5 times an hour. A tram has 60 seats and a 125 standing spaces [@(GVB, 2023; Wikipedia-bijdragers, 2022)]. The capacity of public transport is calculated below.\n\n# Our endpoint and startpoint were assigned earlier as\n# finish_swim and start_swim\n# The center coordinates are calculated above as avg_lon, avg_lat\n\ntime_seconds = 10*60\nspeed = 4*1000/3600\nwdistance = time_seconds * speed\nprint(wdistance)\n\n# we calculate centrality for the street network around the swimming route\n# and include the nodes at 666m distance. \n# we use network_type is all to include the bridges around Marine terrain\n\ncentral_finish = ox.graph.graph_from_point(finish_swim, dist = wdistance,\n                                           network_type='all')\ncentral_start = ox.graph.graph_from_point(start_swim, dist = wdistance,\n                                          network_type='all')\n\n#find nearest nodes to the coordinates of the finish and headquarter\nclosest_finish = ox.distance.nearest_nodes(central_finish, df.longnum[16],\n                                           df.latnum[16], return_dist=True)\nprint(closest_finish)\n\nclosest_start = ox.distance.nearest_nodes(central_start, df.longnum[0],\n                                          df.latnum[0], return_dist=True)\nprint(closest_start)\n\ncentrality_finish = nx.closeness_centrality(central_finish, 46366390)\ncentrality_start = nx.closeness_centrality(central_start, 46365861)\nprint(\"The centrality of the finish is\", centrality_finish,\n      \", and the centrality of the start is\", centrality_start)\n\n666.6666666666667\n(46366390, 6823208.798913781)\n(46365861, 6823644.953020242)\nThe centrality of the finish is 0.0 , and the centrality of the start is 0.0390860200493787\n\n\n\nThe low numbers mean that the ‘finish_swim’ and ‘start_swim’ are easily accesible as a lower centrality number means the nodes are better connected."
  },
  {
    "objectID": "energy.html",
    "href": "energy.html",
    "title": "Energy",
    "section": "",
    "text": "The Municipality is worried that the canal and support boats might pollute the air with their diesel engines. Since the Municipality wants to create ideal conditions for the swimmers so that they can set records, we need to see if their concern is warranted and what should or could be done to improve conditions. Amsterdam also wants to advertise this event as a Neutral Energy Event (NEE).\nHere we list some key information in regards to how we tackled the problem of planning such event. The following chart presents the key elements to know, their sources and their formats."
  },
  {
    "objectID": "energy.html#minimising-exposure-to-pollution-from-dieselfossil-fuel-driven-boats",
    "href": "energy.html#minimising-exposure-to-pollution-from-dieselfossil-fuel-driven-boats",
    "title": "Energy",
    "section": "Minimising exposure to pollution from diesel/fossil fuel driven boats",
    "text": "Minimising exposure to pollution from diesel/fossil fuel driven boats\n\nNo. of diesel/fossil fuel driven canal boats\nAs of 2020, there are about 12 550 boats in the canals of Amsterdam, approximately 550 of which are commercial boats, the remaining 12000 are recreational boats. Of the commercial fleet about 75% is emission free, while for recreational boats this percentage is only 5%. (Sterling 2020)\n\n\n\nType\nNo. of boats\n% of boats that are emission free\n\n\n\n\nCommercial\n550\n75\n\n\nRecreational\n12550\n5\n\n\n\n\ncom_boats = 550\nrec_boats = 12550\nperc_com_boats_emission_free = 75\nperc_rec_boats_emission_free = 5\n\ncom_boats_emission_free = com_boats * (perc_com_boats_emission_free/100)\nrec_boats_emission_free = rec_boats * (perc_rec_boats_emission_free/100)\n\nboats_emission_free = com_boats_emission_free + rec_boats_emission_free\nboats_emission = com_boats + rec_boats - boats_emission_free\n\nprint(\"The number of emission free boats is\", int(boats_emission_free))\nprint(\"The number of  boats with emission is\", int(boats_emission))\n\n\n\nPeak times for canal boats\nTo create ideal conditions for the swimmers, we look towards hosting the event outside of ‘rush hours’ on the canals, to minimise impact of pollution from boats. This would also help ensure the continuity of boat traffic.\nAs can be seen in the figure below (Snelder, Minderhoud, and Calvert 2013) (no raw data available), the busiest hours on the water usually start around 15:00. For that reason the swimming event should be finished before 15:00.\n\n\n\nimage\n\n\nTo determine the ideal start time of the race, we consider the following:\n\nPeople swim at speeds of about 8 km/h. (Thornton 2019)\nRequired length of the swim route is 5km.\nFor safety reasons, each wave of swimmers should have a maximum of 120 swimmers in the group. (Triathlon n.d.)\nWe plan for around 3000 swimmers for the swim meet, similar to the Amsterdam City Swim. (Swim n.d.)\n\n\nLENGTH_OF_ROUTE = 5000  # in meters\nNUM_SWIMMERS_PER_WAVE = 120\nnum_swimmers = 3000\nspeed_swimmers_kmh = 8\ntime_between_waves = 20  # minutes\n\n#  save variable so it can be accessed from other notebooks\n%store LENGTH_OF_ROUTE\n%store num_swimmers\n%store NUM_SWIMMERS_PER_WAVE\n%store speed_swimmers_kmh\n\nspeed_swimmers_ms = speed_swimmers_kmh * 1000 / (60*60)\nnum_waves = num_swimmers / NUM_SWIMMERS_PER_WAVE\nsec_per_wave = LENGTH_OF_ROUTE / speed_swimmers_ms\nmin_per_wave = sec_per_wave / 60\nduration_swim_min = min_per_wave + (num_waves * time_between_waves)\nduration_swim_hours = duration_swim_min / 60\nend_time = 15.00\nstart_time = end_time - duration_swim_hours\n\nprint(\"The start time for the first wave of swimmers is\",\n      int(start_time),\":00\")\n\nStored 'NUM_SWIMMERS_PER_WAVE' (int)\nStored 'LENGTH_OF_ROUTE' (int)\n\n\nThus, the first wave of the race starts at 6:00 am with a next wave going every 20 minutes, this way the last wave will be out of the water by 15:00."
  },
  {
    "objectID": "energy.html#energy-use-of-boats",
    "href": "energy.html#energy-use-of-boats",
    "title": "Energy",
    "section": "Energy use of boats",
    "text": "Energy use of boats\n\nEnergy requirements for canal boats in general\n\nEnergy use of canal boats compared to driving a car\nLet’s say 10 boats are needed to assist in the city swim, we can calculate how many car-kM’s could be driven as equivalent to the power usage of boats. (Weerd 2023) (marina 2023)\n\nyearly_car_consumption_kWh = 7700\nhours_boat_race = 9\nboat_diesel_usage = 1  # litre per hour\nnum_boats = 10\nenergy_density_diesel = 45  # MJ/kg\nconversion_rate_MJ_kWh = 0.277778  # 1 MJ = 0.277778 kWh\nweight_diesel = 0.84  # kg\n\nkilos_diesel_used = num_boats*boat_diesel_usage*weight_diesel*hours_boat_race\nenergy_use_boats = kilos_diesel_used*energy_density_diesel*conversion_rate_MJ_kWh\nnum_days_car_equivalent = 365/yearly_car_consumption_kWh*energy_use_boats\n\n# print(liters_diesel_used)\n# print(energy_use_boats)\nprint(\"The energy use of 10 boats during the city swim is equal to the \\\n      average car energy consumption in\",num_days_car_equivalent,\"days.\")\n\n\n\nEconomic feasibility of switching canal boats to clean energy\nCost of converting boats to electric: - Building new electric canal boat: 1m euros; - Converting existing canal boat to electrical: 50,000 euros; - Converting recreational boats to electrical: 4,000 – 40,000 euros depending on size; - Installation chargers: 100 boat charging stations installed by end 2021 + floating charging station by Skoon Energy to help with grid balancing\nThe feasibility of electrifying the entire fleet of Amsterdam is completely reliant on the willingness of businesses, private owners and the municipality to invest these amounts of money.\nArticle\n\n\n\nEnergy requirements for support boats for the event\n\nNumber of support boats required\nDrawing on other event data, here we list guidelines and recommendations taken by other organizers in Open Swimming competitions worldwide.\n\n\n\n\n\n\n\n\n\n\n#\nParameter\nSummary\nSource\nFormat\n\n\n\n\n1.\nOpen Water Swimming Manual 2022\n“There must be sufficient safety craft or escort craft located on the course to immediately recognize when a swimmer is in distress and to initiate an immediate rescue response after observation or notification that a swimmer’s rescue is required.\nManual\nManual\n\n\n2.\nOpen Water Swimming Manual 2022\nthere should also be stationary safety craft located every 400 meters along the course, with a CPR- and life support-trained responder on board\nManual\nManual\n\n\n3.\nBritish Triathlon Open Water Swiming Safety Guidelines\n“Safety cover, safety craft and / or canoes must be provided on the water. Personnel assigned to water safety must be in the ratio of 1 to, at most, every 20 competitors. Emergency exit points should be available for swimmers to leave the water and separate exit points should be available for safety craft.”\nGuidelines\nGuidelines\n\n\n\nThe safety of all swimmers must be ensured during the whole duration of the race. During the event safety measures consist of:\n\nLifeguards in canoes;\nAs advised by the Open Water Swimming Safety Guide for Multi-Sport Events from the British Triathlon organisation boats should be in the water to be able to rescue swimmers in distress. A ratio of a minimum of one boat per twenty swimmers is advised in waters where shorelines are easily reachable. A swimmer should also always be within 50 meters range of a lifeguard. (Triathlon n.d.) Since most of the chosen route goes through canals it is deemed unsafe to have boats sailing so close alongside the swimmers. For that reason, lifeguards will be present every 50 meters in canoes instead of on boats.\nThis also contributes to the sustainability of the event. As mentioned previously, diesel engine boats are highly polluting and the resultant water toxicity can remain in the water for up to 14 days after the use of boats (Jüttner et al. 1995), so no fossil fuel boats should be used as support boats.\nSafety platforms in the water;\nTo make sure distressed swimmers can easily leave the water platforms are placed every 100m alongside the swimming route where quay walls make exiting the water difficult.\n\n\nMAX_DISTANCE_BETWEEN_LIFEGUARDS = 50\nNUM_SWIMMERS_PER_SUPPORT_BOAT = 20\n# Retrieve variables stored in other notebooks\n%store -r NUM_SWIMMERS_PER_WAVE\n%store -r LENGTH_OF_ROUTE\n\nnum_boats_required = NUM_SWIMMERS_PER_WAVE / NUM_SWIMMERS_PER_SUPPORT_BOAT\nnum_lifeguards_required = LENGTH_OF_ROUTE / MAX_DISTANCE_BETWEEN_LIFEGUARDS\nnum_lifeguard_canoes_required = max(num_boats_required, num_lifeguards_required)\n\nprint(\"No. of lifeguard canoes required = max({}, {}) = {}\".\n      format(num_boats_required, num_lifeguards_required,\n             num_lifeguard_canoes_required))\n\nNo. of lifeguard canoes required = max(6.0, 100.0) = 100.0\n\n\nKnowing that canals are too narrow for boats to navigate safely with swimmers around, lifeguards alongside the canals, along with platforms every 100m where quay walls are steep would suffice.\n\n\nEnergy requirements for support boats\n100 canoes are used for the safety of swimmers, by using canoes instead of electric boats a lot of greenhouse gas emission is prevented. If we were to use electric boats electricity would have been used. Exactly how much energy we are saving by using canoes is calculated below.\n\nnum_canoes = 100\npower_boat_kwh = 20\ntime_race = 7\n\npower_use = num_canoes * power_boat_kwh * time_race\nprint('Reduced power use of boats:', power_use, 'kWh')\n\nUsed power by boats: 14000 kWh\n\n\n\n\nSolar panels required\nAssuming that solar panels would be rented and installed for a week to power the boats the amount of solar panels needed is calculated below. Numbers about efficiency of solar panels are found at (Voltasolar 2023).\n\nwp_sp = 365\nkWh_year = wp_sp * 0.85\nkWh_week = kWh_year / 52\nsp_needed = power_use / kWh_week\nprint('Number of solar panels needed:', int(sp_needed) + 1)\n\nNumber of solar panels needed: 2347\n\n\nIf the city were to actually use electrified boats the solar panels that are needed to harvest the energy could be placed on the water. (floatingsolar 2023) has a circular system that floats. The size of the floating solar field is calculated below.\n\nimport math\n\narea_circle = 2347.0 * 1.65\n# surface = 3.14 * r^2\nr = math.sqrt(area_circle / 3.14)\ndiameter = 2 * r\n\nprint(\"The diameter of the floating solar panels is\", diameter, \"m\")\n\nThe circle needs to have a diameter of about 70m, this fits in the water close to the marine terrain as shown on the picture below.\n\n\n\ndiameter solar.JPG"
  },
  {
    "objectID": "energy.html#pollution-impact-of-boats",
    "href": "energy.html#pollution-impact-of-boats",
    "title": "Energy",
    "section": "Pollution impact of boats",
    "text": "Pollution impact of boats\nDue to the lack of exhaust gas treatment systems in boat engines, as found in all modern car engines, a modern 5 horsepower 4-stroke outboard engine can be as polluting as 39 passenger cars driving at 95 km/h. (Propel 2022) While we do not know the detailed relationship between boat traffic and water quality, we do know that water toxicity as a result of fossil fuelled boats can stay present up to 14 days after the use of boats (Jüttner et al. 1995).\nAs such, water quality should improve if there are fewer or no canal boats using fossil fuels for at least two weeks prior to the event."
  },
  {
    "objectID": "energy.html#conclusion",
    "href": "energy.html#conclusion",
    "title": "Energy",
    "section": "Conclusion",
    "text": "Conclusion\nThe swim meet is proposed to be conducted from 06:00 to 15:00 pm, with the following route:\n\n\n\nRoute 3"
  },
  {
    "objectID": "water.html",
    "href": "water.html",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "",
    "text": "To host an open water swim meet in the canals of Amsterdam, we must first ensure that the water quality is good enough for swimming. Unfortunately, only official bathing sites in the Amsterdam canals are monitored for water quality. (Waternet n.d.) Thus, there is limited data available.\nWe do know that there are various factors that affect the quality of water, such as sewage overflows, water currents, temperature and more (Tillaart 2017). If we had data sampled at appropriate locations and sufficient background knowledge, we would use a model to estimate water pollution levels and how they are affected by weather and canal traffic. For now, we will use the available data for some basic analysis."
  },
  {
    "objectID": "water.html#datasets-found",
    "href": "water.html#datasets-found",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "Datasets found",
    "text": "Datasets found\nHere is the list of datasets we have identified with regards to water pollution levels, along with the relevant available sources (if existant) of information and their formats.\n\n\n\n\n\n\n\n\n\n\n#\nParameter\nExplanation\nSource\nFormat\n\n\n\n\n1.\nPollution levels in Herensgracht and Prinsengracht\nChemical composition of the water\nStudy\nJournal\n\n\n2.\nPollution levels in swimming locations\nChemical levels in swimming locations in 2019 with interpreted data\nDataset\nExcel\n\n\n3.\nPlaces with sensors available.\n \n \n \n\n\n4.\nHistorical data for water quality.\n \n \n \n\n\n5.\nSewage overflows\nUsed Python script to convert file to Geojson.\nDataset\nJSON\n\n\n6.\nCanal traffic\nTraffic densities of canals\nReport\nImage\n\n\n\n\nSewage overflows\nSince Amsterdam uses a combined sewage system, sewage overflows are a major source of water pollution after heavy rain. (Tillaart 2017) We can see if there areas without sewage overflow points in the canals.\nThe Waternet sewerage network data is available on Overheid.nl. Unfortunately, the download link for the WFS data returned a 404 error. Instead, we used the provided API to retrieve the sewage nodes, then saved it to sewer_nodes.geojson. We then filtered the data to get the sewage overflow nodes and saved it to sewage_overflow_nodes.geojson.\n\nimport geopandas as gpd\nimport json\nimport os.path\nfrom pyproj import Transformer\nimport requests\nimport time\n\nFILENAME_SEWER_NODES = \"data/sewer_nodes.geojson\"\nFILENAME_SEWAGE_OVERFLOW_NODES = \"data/sewage_overflow_nodes.geojson\"\nURL_SEWER_NODES = (\"https://api.data.amsterdam.nl/v1/leidingeninfrastructuur/\"\n                   \"waternet_rioolknopen/?page_size=1000\")\nSEWAGE_OVERFLOW_TYPES = [\n    \"Uitlaat gemengde overstort\",  # Mixed overflow\n    \"Uitlaat vuilwater nooduitlaat\",  # Black water emergency outlet\n    \"(Externe) overstortput\",  # (External) overflow\n    \"Overstort met signalering\",  # Overflow with signaling\n    \"Interne overstortput\",  # Internal overflow\n    \"Nooduitlaat met signalering\"  # Emergency overflow with signaling\n]\n\n\ndef get_sewer_nodes(url, geojson_filename, is_test_run=False):\n    \"\"\"Return sewer nodes as geodataframe, read from the GeoJSON file.\n    If file does not exist, retrieve the data from the API and save results to\n    the GeoJSON file. If this is a test run and the API is called, only partial\n    results will be retrieved from the API.\n\n    Parameters:\n        url: API endpoint for sewage networks data\n        geojson_filename: file containing (or will contain) the saved data\n        is_test_run: if True, limit number of API requests made (for debugging)\n    \"\"\"\n\n    if os.path.exists(geojson_filename):\n        print(\"Sewer nodes data has already been parsed to GeoJSON in '{}'\"\n              .format(geojson_filename))\n        gdf = gpd.read_file(geojson_filename)\n    else:\n        print((\"Sewer nodes GeoJSON file does not exist. \"\n               \"Requesting data from API{}\").format(url))\n        geojson_data = retrieve_sewer_nodes_data_from_api(url, is_test_run)\n\n        # Save data for future use\n        with open(geojson_filename, \"a+\", encoding='utf-8') as outfile:\n            json.dump(geojson_data, outfile)\n        print(\"Sewer nodes data saved to file '{}'\".format(geojson_filename))\n\n        gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n    return gdf\n\n\ndef retrieve_sewer_nodes_data_from_api(url, is_test_run=False):\n    \"\"\"Return sewer nodes data as GeoJSON.\n    In test runs, limit the number of API requests made.\"\"\"\n\n    data_entries = request_sewer_nodes_data_from_api(url, is_test_run)\n    geojson_data = parse_sewer_node_results(data_entries)\n\n    return geojson_data\n\n\ndef request_sewer_nodes_data_from_api(url, is_test_run=False):\n    \"\"\"Retrieve all sewer node results from API.\n    For test runs, stop after first 3 pages of results.\"\"\"\n\n    api_response = requests.get(url, headers={'User-Agent': 'data1'}).json()\n\n    sewer_node_entries = []\n    num_pages_requested = 0\n\n    while api_response is not None:\n        time.sleep(0.5)  # avoid spamming server\n        data = api_response[\"_embedded\"][\"waternet_rioolknopen\"]\n        sewer_node_entries += data\n\n        if \"next\" in api_response[\"_links\"]:  # has next page of results\n            api_response = requests.get(api_response[\"_links\"][\"next\"][\"href\"],\n                                        headers={'User-Agent': 'data1'}).json()\n        else:  # is last page of results\n            api_response = None\n\n        num_pages_requested += 1\n\n        if is_test_run and num_pages_requested &gt;= 3:\n            break\n\n    return sewer_node_entries\n\n\ndef parse_sewer_node_results(sewer_node_entries):\n    \"\"\"Parse sewer node results from Amsterdam sewer network API to GeoJSON\"\"\"\n\n    transformer = Transformer.from_crs(\"EPSG:7415\", \"EPSG:4326\")\n\n    geojson = {\n        \"type\": \"FeatureCollection\",\n        \"features\": []\n    }\n\n    for entry in sewer_node_entries:\n        x, y, z = entry[\"geometrie\"][\"coordinates\"]\n        lat, lon = transformer.transform(x, y)\n        feature = {\n            \"type\": \"Feature\",\n            \"geometry\": {\n                \"type\": \"Point\",\n                \"coordinates\": [lon, lat]\n            },\n            \"properties\": {\n                \"id\": entry[\"id\"],\n                \"typeKnoop\": entry[\"typeKnoop\"]\n            }\n        }\n        geojson[\"features\"].append(feature)\n\n    return geojson\n\n\ndef get_sewage_overflow_nodes(url,\n                              sewer_nodes_filename,\n                              sewage_overflow_nodes_filename,\n                              is_test_run):\n    \"\"\"Return sewage overflow points as geodataframe read from the\n    GeoJSON file. If file does not exist, get and process the sewer nodes data,\n     then save results to the GeoJSON file.\n\n    Parameters:\n        url: API endpoint for sewage networks data\n        sewer_nodes_filename: name of GeoJSON file containing (or will contain)\n                              the saved sewer nodes data\n        sewage_overflow_nodes_filename: name of GeoJSON file containing\n                                        (or that will contain) the saved\n                                        sewage overflow nodes data\n        is_test_run: if True, limit number of API requests made (for debugging)\n    \"\"\"\n\n    if os.path.exists(sewage_overflow_nodes_filename):\n        print(\"Sewage overflow nodes data already exists in file '{}'\"\n              .format(sewage_overflow_nodes_filename))\n        gdf_overflows = gpd.read_file(sewage_overflow_nodes_filename)\n    else:\n        gdf_sewer_nodes = get_sewer_nodes(url, sewer_nodes_filename,\n                                          is_test_run)\n        gdf_overflows = gdf_sewer_nodes[gdf_sewer_nodes[\"typeKnoop\"]\n                                        .isin(SEWAGE_OVERFLOW_TYPES)]\n        gdf_overflows.to_file(sewage_overflow_nodes_filename)\n        print(\"Sewage overflow nodes data saved to file '{}'\"\n              .format(sewage_overflow_nodes_filename))\n    return gdf_overflows\n\n\npgdf_overflows = get_sewage_overflow_nodes(\n    URL_SEWER_NODES, FILENAME_SEWER_NODES, FILENAME_SEWAGE_OVERFLOW_NODES,\n    is_test_run=False\n)\n\nWe then plot the sewage overflow points on a map.\n\nimport folium\n\nmap_of_sewage_overflow_nodes = pgdf_overflows.explore(\n    legend=True,\n    name=\"Sewage Overflow Points\",\n)\n\nfolium.TileLayer(\"CartoDB positron\", show=False).add_to(\n    map_of_sewage_overflow_nodes\n)\n\nmap_of_sewage_overflow_nodes\n\nObserve that there are fewer sewage overflow points in the northeast area of Amsterdam’s canals, near Marineterrein. Assuming water pollution dissipates quickly with distance from the sewage overflow point, we can choose a route that avoids most of the sewer nodes to ensure better water quality for the swim.\n\n\nCanal Traffic\nBoat traffic is another source of water pollution. Due to the lack of exhaust gas treatment systems in boat engines, as found in all modern car engines, a modern 5 horsepower 4-stroke outboard engine can be as polluting as 39 passenger cars driving at 95 km/h. (Propel 2022) As of 2020, there are about 12 550 boats in the canals of Amsterdam, approximately 550 of which are commercial boats, the remaining 12000 are recreational boats. Of the commercial fleet about 75% is emission free, while for recreational boats this percentage is only 5%. (Sterling 2020)\nWhile we do not know the detailed relationship between boat traffic and water quality, we do know that water toxicity as a result of fossil fuelled boats can stay present up to 14 days after the use of boats (Jüttner et al. 1995). Thus, one possibility is to limit the number of fossil fuelled boats in the two weeks prior to the event."
  },
  {
    "objectID": "water.html#choosing-a-route",
    "href": "water.html#choosing-a-route",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "Choosing a route",
    "text": "Choosing a route\nSince the Amsterdam City Swim is held annually in the canals, this suggests that an open water swim is feasible. However, we will need to find a suitable 5km route. We have been told to ensure that the event does not impact commercial water transport, and has a small impact on the canal boat routes.\n\nCanal traffic\nTo minimise impact on boat routes, we look for a route that avoids areas of high canal traffic. This would also result in a route with cleaner water.\nWaternet commissioned TNO to produce a model to predict traffic densities in the canal. (Snelder, Minderhoud, and Calvert 2013) The prediction results from the model are as follows (image only, as we do not have access to the raw data):\n\n\n\nimage\n\n\n\n\nAmsterdam City Swim\nWe take reference from the Amsterdam City Swim, which is held every summer in the canals of Amsterdam. We have the routes for 2019 and 2023, both of which are the same, other than the direction.\n\n\n\nAmsterdam City Swim 2019 route\n\n\n\n\n\nAmsterdam City Swim 2023 route\n\n\n\n\n\nAmsterdam City Swim 2019 & 2023 routes\n\n\n\n\nIdentifying potential routes\nBased on the City Swims, Amsterdam Oost seems to be a suitable area for open water swimming events. Visual comparison also shows that Amsterdam Oost has relatively fewer sewage overflow points and less canal traffic.\n\n\n\nAmsterdam Oost\n\n\nThus, we have identified 3 potential 5km routes in this area, indicated in the images below. Our recommendation is the third route, as it traverses the fewest number of sewage overflow points.\n\n\n\nRoute 1\n\n\n\n\n\nRoute 2\n\n\n\n\n\nRoute 3"
  },
  {
    "objectID": "water.html#recommendations",
    "href": "water.html#recommendations",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "Recommendations",
    "text": "Recommendations\nWe propose the following route, which traverses the fewest number of sewage overflow nodes and avoids areas with high traffic.\n\n\n\nRoute 3\n\n\nHowever, since Waternet recommends people to avoid swimming in the waters for 3 days after heavy rainfall (Waternet n.d.), we would recommend finding an alternative backup route in case there is heavy rainfall prior to the event. It would also be better for water quality should fossil fuelled boats be banned from the area for two weeks before the event, though this may not be economically feasible."
  },
  {
    "objectID": "water.html#auto-generated-routes",
    "href": "water.html#auto-generated-routes",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "Auto-generated routes",
    "text": "Auto-generated routes\nAfter selecting a route manually, we also prepared a script to automatically identify potential routes for the swim. This appendix describes the process, as well as a comparison between the routes found manually and automatically.\n\nFinding potential routes\nHere is the list of datasets we have identified, along with the relevant available sources and their formats.\n\n\n\n\n\n\n\n\n\n\n#\nParameter\nExplanation\nSource\nFormat\n\n\n\n\n1.\nSewage overflows\nUsed Python script to convert file to Geojson.\nDataset\nJSON\n\n\n6.\nEmbarkation and disembarkation points\nProxy for canal traffic\nDataset\nGeoJSON\n\n\n\nSteps:\n\nCreate the network of potential canals in Amsterdam, excluding canals with high shipping traffic.\nFor each waterway (excluding canals with high shipping traffic), count the number of embarkation/disembarkation points and sewage overflow points that lie nearby.\nFind all possible 5 km routes starting from the Marineterreine swimming area, keeping track of the number of embarkation/disembarkation points and sewage overflow points for each route.\nSort the 5 km routes by the number of embarkation/disembarkation points, then by the number of sewage overflow points.\nPlot the top 10 routes on a map for comparison.\n\n\nCreate network of traversable canals for the open swim meet\n\nimport osmnx as ox\n\n# Import canals of Amsterdam, excluding waterways with high shipping traffic\nams_canals = ox.graph_from_place(\n    'Amsterdam, Netherlands',\n    custom_filter=('[\"waterway\"~\"canal|river|ditch\"]'\n                   '[\"name\"!~\"IJ|Noordzeekanaal|Amsterdam-Rijnkanaal\"]'))\n\nox.graph_to_gdfs(ams_canals, nodes=False).explore()\n\n\n\nCount number of points of interest that lie near each waterway\n\ndef count_points_close_to_lines(lines, points, buffer_dist, counts_label):\n    \"\"\"Count the number of points that lie within buffer area of each line\"\"\"\n    # Based on code from https://stackoverflow.com/a/54128782\n\n    lines_with_counts = lines.copy()\n    spatial_index = points.sindex\n    results_list = []\n\n    for index, line in lines.iterrows():\n        buffer = line['geometry'].buffer(buffer_dist)\n        # Find approximate matches with r-tree,\n        possible_matches_index = list(\n            spatial_index.intersection(buffer.bounds))\n        possible_matches = points.iloc[possible_matches_index]\n        # then use the results to find precise matches\n        precise_matches = possible_matches[possible_matches.intersects(buffer)]\n        results_list.append(len(precise_matches))\n\n    lines_with_counts[counts_label] = results_list\n\n    return lines_with_counts\n\n\ngdf_overflows = gpd.read_file(\"./data/sewage_overflow_nodes.geojson\")\ngdf_embarks = gpd.read_file(\"./data/disembarking_points.json\")\n\n# Project geometries so distances are in meters\nproj_ams_canals = ox.project_graph(ams_canals)\npgdf_ams_canals = ox.graph_to_gdfs(proj_ams_canals, nodes=False)\npgdf_overflows = ox.projection.project_gdf(gdf_overflows,\n                                           to_crs=proj_ams_canals.graph['crs'])\npgdf_embarks = ox.projection.project_gdf(gdf_embarks,\n                                         to_crs=proj_ams_canals.graph['crs'])\n\ngdf_ams_canals_w_counts = count_points_close_to_lines(pgdf_ams_canals,\n                                                      pgdf_overflows,\n                                                      65,\n                                                      'num_overflows')\n\ngdf_ams_canals_w_counts = count_points_close_to_lines(gdf_ams_canals_w_counts,\n                                                      pgdf_embarks,\n                                                      65,\n                                                      'num_embarks')\n\n\n\nView no. of overflow points for each canal\n# We use this map to visually check if the buffer distance is reasonable.\n\nmap_ams_canals_overflows = gdf_ams_canals_w_counts.explore(\n    column='num_overflows',\n    cmap='viridis_r',\n    tiles=\"CartoDB positron\")\npgdf_overflows.explore(m=map_ams_canals_overflows, style_kwds={\"opacity\": 0.5})\n\n\n\n\nView no. of embarkation points for each canal\nmap_ams_canals_embarks = gdf_ams_canals_w_counts.explore(\n    column='num_embarks', cmap='viridis_r', tiles=\"CartoDB positron\")\npgdf_embarks.explore(m=map_ams_canals_embarks, style_kwds={\"opacity\": 0.5})\n\n\n\n\nFind 5km routes and score each route\nFor simplicity, we find the shortest path that is at least 5 km long instead of finding paths that are exactly 5 km long. To get the exact length, we will need to create a new node at the required location and split edges accordingly, which is more complicated.\nNote that this means the scores computed for each route may not be accurate. For example, routes which are much longer than 5km due to the last edge being very long might have many overflow points from the excess part of the route.\nWhile finding the routes, we also compute the scores for each route. Any column name in the geodataframe gdf_with_scores (that contains numeric values) can be used for scoring. The score of a route is the sum of its values for all edges in the route.\n\ndef find_routes_of_length_w_scores(start_node, graph, length,\n                                   score_names, gdf_with_scores):\n    \"\"\"Finds all (shortest possible) routes that are at least the\n    specified length.\n\n    Parameters:\n        start_node: start node of routes\n        graph: nx graph for finding paths\n        length: min length of route\n        score_names: list of column names in gdf_with_scores.\n                     The values for edges in the route will be summed\n                     to obtain a score for the route.\n        gdf_with_scores: dataframe containing scores for each edge\n\n    Returns:\n        (routes, scores): list of routes, where a route is a list of\n                          traversed edges, and\n                          list of scores, containing one score for\n                          each score name\n    \"\"\"\n\n    invalid_score_names = list(filter(lambda x:\n                                      x not in gdf_with_scores.columns,\n                                      score_names))\n\n    if len(invalid_score_names) &gt; 0:\n        raise Exception(\"Score name(s) missing from gdf_with_scores: {}\"\n                        .format(\", \".join(invalid_score_names)))\n\n    def find_routes_containing_path(curr_node, curr_path,\n                                    curr_length, curr_weights, graph):\n        if curr_length &gt; length:  # found valid route\n            return [curr_path], [curr_weights]\n\n        traversed_nodes = [edge[0] for edge in curr_path] + [curr_node]\n        prev_node = curr_path[-1][0] if len(curr_path) &gt; 0 else None\n        incident_edges = graph.edges(curr_node, keys=True)\n        routes_containing_curr_path = []\n        route_scores = []\n\n        for edge in incident_edges:\n            if edge[1] in traversed_nodes:  # avoid loops\n                continue\n\n            new_path = curr_path + [edge]\n            edge_length = graph.edges[edge][\"length\"]\n            edge_data = gdf_with_scores.loc[edge]\n            new_weights = [curr_weights[i] + edge_data[score_name]\n                           for i, score_name in enumerate(score_names)]\n            routes_with_new_node, scores = find_routes_containing_path(\n                edge[1],\n                new_path,\n                curr_length + edge_length,\n                new_weights, graph)\n            routes_containing_curr_path.extend(routes_with_new_node)\n            route_scores.extend(scores)\n\n        return routes_containing_curr_path, route_scores\n\n    return find_routes_containing_path(start_node, [], 0,\n                                       [0 for x in score_names], graph)\n\nWe find all routes of length at least 5 km, and score using the number of sewage overflow nodes and number of embarkation/disembarkation points along the route.\n\n# Use Marineterrein pool as start point\nlat, lon = 52.37343358243731, 4.916215248650945\nstart_node = ox.distance.nearest_nodes(ams_canals, lon, lat, return_dist=False)\n\nroutes, scores = find_routes_of_length_w_scores(start_node, ams_canals, 5000,\n                                                ['num_overflows',\n                                                 'num_embarks'],\n                                                gdf_ams_canals_w_counts)\nprint(\"Found {} routes.\".format(len(routes)))\n\nNext, we rank the routes by number of embarkation/disembarkation points, then by number of sewage overflow nodes. We prioritise impact on canal traffic over sewage overflows, as sewage overflows are a risk only in heavy downpour.\n\nimport pandas as pd\n\ndf_scored_routes = pd.DataFrame({\n    'id': range(len(routes)),\n    'edge_list': routes,\n    'num_embarks': [score[1] for score in scores],\n    'num_overflows': [score[0] for score in scores],\n})\n\nranked_routes = df_scored_routes.sort_values(['num_embarks', 'num_overflows'])\ntop_route_ids = ranked_routes['id'].tolist()[0:10]\n\nranked_routes[0:10]\n\nThen, we plot the routes on the map.\n\n\nPlot top 10 routes on map\n# workaround, otherwise calling folium.plugins directly gives an error\nimport folium.plugins as plugins\n\n\ndef edge_list_to_gdf(graph, edge_list):\n    node_list = [x for (x, y, k) in edge_list]\n    node_list.append(edge_list[-1][1])\n    return ox.utils_graph.graph_to_gdfs(\n        graph.subgraph(node_list), nodes=False).loc[edge_list]\n\n\ngdf_routes = [edge_list_to_gdf(ams_canals, routes[id]) for id in top_route_ids]\n\ncomplete_map = folium.Map(tiles=\"cartodbpositron\",\n                          location=(lat, lon),\n                          zoom_start=14)\n\nfor i in range(min(10, len(gdf_routes))):\n    folium.GeoJson(\n        gdf_routes[i].to_json(),\n        name=\"Route {}\".format(i + 1),\n        style_function=lambda feature: {\n            \"weight\": 3,\n            \"opacity\": 0.3,\n            \"color\": \"#1AC938\",\n        },\n        show=(i &lt; 1)\n        ).add_to(complete_map)\n\n# Plot points as circles, see https://stackoverflow.com/a/65836395\nfolium.GeoJson(gdf_embarks.to_json(),\n               marker=folium.CircleMarker(radius=3,  # in meters\n                                          weight=0,  # outline\n                                          fill_color=\"#023EFF\",\n                                          fill_opacity=0.7),\n               name=\"Embarkation points\").add_to(complete_map)\nfolium.GeoJson(gdf_overflows.to_json(),\n               marker=folium.CircleMarker(radius=3,\n                                          weight=0,\n                                          fill_color=\"#FF7C00\",\n                                          fill_opacity=0.7),\n               name=\"Sewage overflow points\").add_to(complete_map)\n\nfolium.LayerControl().add_to(complete_map)\n\ncomplete_map\n\n\n\n\nAnalysis\n\nGenerated routes go north; manually selected routes go south\nIt is interesting to note that all the top ten routes went northwards, as opposed to our three routes which went southwards.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile we did use embarkation/disembarkation points instead of canal traffic data, the northern route has a traffic density of 0%, so the northern route seems to be a better choice in terms of having fewer sewage overflow points and also smaller impact on canal traffic.\nHowever, the available datasets consider only a limited number of factors. While we did not explicitly state this, the reason we avoided the northern route was because it goes through an area of Marineterrein which is contaminated by oil, heavy metals, tar-like substances and PAHs (Vijsel 2012). This has a critical impact on the water quality, yet is not captured by the datasets.\nFurthermore, while selecting our routes, we took reference from the Amsterdam City Swim route, since the organizers would have considered other factors that we might have missed out on.\n\n\n\nUnexpected results highlight implicit assumptions and expectations\nCode considers only what is stated; humans use context and background knowledge. The automatically generated routes did not match our manually generated routes even though we seemed to be considering the same factors, because we considered other factors in our selection that we may not even be explicitly aware of.\nFor example, the code originally allowed for loops in the routes (allow nodes to be visited twice), so that we could obtain routes similar to our third proposed route. However, this resulted in counter-intuitive routes that seem less pleasant and harder to manage, such as the below route.\n\n\n\nRoute 3\n\n\nAs such, we disallowed loops instead. This also reduced time required since the search space is smaller. However, we may miss out some feasible routes.\n\n\nConstraints imposed by the dataset\nBesides the limitations mentioned in previous sections, the structure of the network also constrains the possible routes. For example, the lake in Sloterplas is represented using a single line, which rules out the possibly of swimming around the circumference of the lake.\n\n\n\nSloterplas waterway\n\n\n\n\n\nConclusion\nUsing a program to find routes allowed us to search more comprehensively in less time. However, the program is constrained by the assumptions built into the code, as well as the provided datasets. We often consider multiple factors in our decisions, without necessarily being aware of those factors. Automating the process made our assumptions and considerations much more explicit.\nGiven more time and resources, we would use these identified gaps as a guide to look for more data. Through repeated iterations, we can hopefully find a solution that humans may miss out (since we are less thorough), but that considers the broad set of factors that we use.\nNonetheless, data can be hard to collect and datasets hard to find, and not all intuitions can be easily made explicit. Perhaps this is where machine learning combined with human judgement can take us further."
  },
  {
    "objectID": "water.html#references",
    "href": "water.html#references",
    "title": "(Swim) water quality of Amsterdam canals",
    "section": "References",
    "text": "References\n\n\nJüttner, Friedrich, Diedrich Backhaus, Uwe Matthias, Ulf Essers, Rolf Greiner, and Bernd Mahr. 1995. “Emissions of Two- and Four-Stroke Outboard Engines—i. Quantification of Gases and VOC.” Water Research 29 (8): 1976–82. https://doi.org/https://doi.org/10.1016/0043-1354(94)00330-A.\n\n\nPropel. 2022. “Why Amsterdam Is a Perfect Example of Cities Going Carbon-Neutral.” Why Amsterdam Is a Perfect Example of Cities Going Carbon-Neutral. https://propel.me/nl/article/why-amsterdam-is-a-perfect-example-of-cities-going-carbon-neutral/.\n\n\nSnelder, Maaike, Michiel Minderhoud, and Simeon Calvert. 2013. “Op de Amsterdamse Grachten, Hebben Wij Nu de Drukte in de Hand, Amsterdam ...” November.\n\n\nSterling, Toby. 2020. “Amsterdam’s Boats Go Electric Ahead of 2025 Diesel Ban.” Reuters, March. https://www.reuters.com/article/us-climate-change-netherlands-idUSKBN20Q1W7.\n\n\nTillaart, Amber van den. 2017. “(Swim) Water Quality Modelling in the City of Amsterdam,” February.\n\n\nVijsel, Annemarie van de. 2012. “Het Marineterrein: Verontreinigde Toplocatie.” Nieuw Amsterdams Peil. https://www.napnieuws.nl/2012/11/08/het-marineterrein-een-verontreinigde-toplocatie/.\n\n\nWaternet. n.d. “Swimming.” Accessed October 14, 2023. https://www.waternet.nl/en/our-water/safe-swimming/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a website created as an assignment for YMS31303 Metropolitan Data 1, one of the courses required for the MSc. Metropolitan Analysis Design and Engineering at the AMS Institute in Amsterdam.\n\nAssignment:\nParis is hosting the Paralympics in 2024. One of the events at the Paralympics is an open water swimming event in the Seine (apparently the water is clean or so the French say). Since the City of Amsterdam thinks it is better than Paris, they want to host an event before the Paralympics, snubbing the Parisians. The idea is to host a 5km. open water swimming event through the canals of Amsterdam. You are asked by the municipality of Amsterdam to advise on the feasibility of the event from the perspective of the safety of the partaking athletes from an environmental perspective. The event is going to be hosted in May.\n\n\nTeam members\n\nChua, Ka Yi\nCorona, Juan José\nvan Winkelen, Youri"
  },
  {
    "objectID": "airbnb_listings_JJ.html",
    "href": "airbnb_listings_JJ.html",
    "title": "Note:",
    "section": "",
    "text": "---\ntitle: \"Housing\"\nformat: html\nbibliography: references.bib\n---\n\nBefore running this notebook, please download listings.csv.gz and place the extracted listings.csv in the data directory.\n\nAssignment 3 : Housing\n\nPreliminary Data\n\nThe following infomation was found prior to the start of the assignment in order to use it.\ntax hotels = 7% of turnover + 3 euros per room tax airbnb = 10% = 3 euros number of visitors = 30000\nLibrary imports and DataFrame generation\n\nimport pandas as pd\nimport geopandas as gpd\n\ncsv_data = list()\nlistings = open(\"C:/Users/jjcor/Downloads/listings_full.csv\",'r', encoding='latin1') #\"./data/listings.csv\"\nfor line in listings:\n    data = line.split(',')\n    csv_data.append(data)\n\nlistings.close()\n\ndf = pd.read_csv(\"C:/Users/jjcor/Downloads/listings_full.csv\", encoding='latin1')\n\n\n\n1. What Amsterdam will receive from tourist tax if the event lasts a week and you will have 30.000 visitors?\n\n\nPseudocode\n\nDiscard listings with minimum stays of more than 7 nights\nSum the total ammount of people that fit the remaining airbnbs accomodate (#19812)\nCalculate average price of accomodation remaining listings\nfor the remaining visitors (11188) they will stay in hotels –&gt; average of 2.2 beds per room\nDivide the number of rooms between the remaining tourists\nMultiply number of available beds to average price\nSum airbnb + hotels taxes accordingly\n\n\n#Gathering information shortcuts:\n \n#ok_listings = pd.DataFrame(df.columns)\n#print(df.columns)\n#print(df.columns[34])\n#print(df.maximum_nights)\n\n\n\n\nCode:\n\n#we discard listings with minimum stays of more than 7 nights\nok_listings = df[(df['minimum_nights'] &lt; 8)].copy()\n\n#we check that all numeric values in our DataFrame sum\ntest = ok_listings.sum(axis=0,numeric_only=True)\n\n#we sum individually the column 'accommodates' so we can retrieve the number of people who can stay \nno_ppl = ok_listings.accommodates.sum()\n\nprint('Number of Airbnb listings with at most 7 days of minimal nights :', no_ppl)\n#print(test) success\n\ntourists = 30000\n\ntourists_hotel = tourists-no_ppl\n\nprint('Number of people who needs to stay in hotel rooms',': ', tourists_hotel)\n#print(ok_listings)\n\n#Average cost of overnight accommodation in Amsterdam in the Netherlands from January 2019 to June 2023\n##https://www.statista.com/statistics/614061/overnight-accommodation-costs-amsterdam-city/\n\nhotel_price_per_night = 294\n\n#https://www.cbs.nl/en-gb/figures/detail/84040ENG\n#Hotels; capacity, type of accommodation, beds, star rating\n\nhotel_rooms_ams = 41840\nhotel_beds_ams = 90918\n\navg_beds_per_room = hotel_beds_ams/hotel_rooms_ams\n\n#print(avg_beds_per_room)\n\n#Number of hotel rooms used by tourists who don't fit in airbnbs\nno_hotel_rooms_used = tourists_hotel/avg_beds_per_room\n\nrevenue_hotels = no_hotel_rooms_used*hotel_price_per_night\n\ntax_hotels = revenue_hotels * 0.07 + no_hotel_rooms_used * 3\n\n#getting rid of $ signs in column\nnew_price = df['price'].str.slice(1,-1)\n\n#adding new_price as a column in our dataframe\nok_listings['new_price'] = new_price\n\nok_listings['new_price']=ok_listings['new_price'].str.replace(',','')\n\n#converting new column values to float so we can math it up =P\nok_listings['new_price'] = ok_listings['new_price'].astype(float)\n\n#calculating total revenue of airbnb by summing all location price per night and then times 7 (number of days in a week)\nrevenue_airbnb = ok_listings.new_price.sum()*7\n\ntax_airbnb = float(revenue_airbnb)*.1 + float(len(new_price)*3)\n\nprint('Total tax revenue from Airbnb locations $', tax_airbnb)\nprint('Total tax revenue from hotel rooms $',tax_hotels)\n\ntotal_revenue = tax_airbnb + tax_hotels\n\nprint('Total tax revenue gathered for the government', total_revenue)\n\nNumber of Airbnb listings with at most 7 days of minimal nights : 23407.0\nNumber of people who needs to stay in hotel rooms :  6593.0\nTotal tax revenue from Airbnb locations $ 1469366.9000000001\nTotal tax revenue from hotel rooms $ 71543.25226687785\nTotal tax revenue gathered for the government 1540910.152266878\n\n\n\n\n2. Plot the amount of AirBnB locations per neighbourhood.\n\n\nPseudocode\n\nFilter from dataframe the locations of airbnb\nGather the different categories inside the column neighourhood\nSum each category inside neighbourhood\n\n\n#It can't get mpre efficient than this\nimport plotly.express as px\n#table = ok_listings.neighbourhood_cleansed.value_counts()\nre_index = ok_listings['neighbourhood_cleansed'].value_counts().reset_index().rename(columns={\"index\": 'neighbourhood', 0 : 'count'})\nprint(re_index )\n\n                    neighbourhood_cleansed  count\n0                   De Baarsjes - Oud-West   1329\n1                             Centrum-West    973\n2                  De Pijp - Rivierenbuurt    898\n3                             Centrum-Oost    766\n4                                     Zuid    571\n5                               Westerpark    561\n6                                 Oud-Oost    475\n7                            Bos en Lommer    399\n8                                Oud-Noord    389\n9   Oostelijk Havengebied - Indische Buurt    304\n10                         Watergraafsmeer    249\n11                              Noord-West    212\n12                IJburg - Zeeburgereiland    173\n13                             Slotervaart    156\n14                              Noord-Oost    135\n15                 Geuzenveld - Slotermeer    110\n16                  Buitenveldert - Zuidas     96\n17                  De Aker - Nieuw Sloten     67\n18                         Bijlmer-Centrum     47\n19                   Gaasperdam - Driemond     45\n20                                  Osdorp     43\n21                            Bijlmer-Oost     37\n\n\n\n#graph with information\nfigure = px.bar(re_index, x='neighbourhood_cleansed', y='count', title =  'Number of airbnbs per neighbourhood in Amsterdam')\nfigure.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n3: Which street in Amsterdam has the most AirBnB apartments?\n\n\nPseudocode\n\nFind the locations of airbnb through lat and long.\nAdd the street category to the DataFrame.\nGather the different categories inside the column Street.\nSum each category per street filter.\n\n\n#pip install geopy\n\nimport certifi\nimport ssl\nimport geopy.geocoders\nfrom geopy.geocoders import Nominatim, Photon\n\n# Workaround to fix SSL certififcate expired error on some laptops\n# Solution taken from https://stackoverflow.com/a/50665487\n# Error message:\n#   GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): \n#   Max retries exceeded with url: /reverse?lat=52.40164&lon=4.95106&format=json&addressdetails=1 \n#   (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] \n#   certificate verify failed: certificate has expired (_ssl.c:1006)')))\nctx = ssl.create_default_context(cafile=certifi.where())\ngeopy.geocoders.options.default_ssl_context = ctx\n\ngeolocator = Photon(user_agent='geoapiExercises')\n\nprint(ok_listings.columns)\n\n#New dataframe with only 3 parameters\ngeolocs_airbnb = ok_listings[['latitude', 'longitude']]\n\n'''\n#here we set up a geodata frame based on the airbnb listings and do so with lat and long as geo location\ngdf_listings = gpd.GeoDataFrame(ok_listings[[\"ï»¿id\", \"neighbourhood\", \"license\"]], geometry=gpd.points_from_xy(ok_listings.longitude, ok_listings.latitude), crs = \"WGS84\")\nprint(gdf_airbnb.head())\n'''\n\ngeolocs_airbnb['longitude']=geolocs_airbnb['longitude'].str.replace(',','')\ngeolocs_airbnb.longitude = (geolocs_airbnb.longitude.str[:1] + geolocs_airbnb.longitude.str[1:]).astype(float)\n\n#print(geolocs_airbnb.longitude)\n\ngeolocs_airbnb['latitude']=geolocs_airbnb['latitude'].str.replace(',','')\ngeolocs_airbnb.latitude = (geolocs_airbnb.latitude.str[:2] + '.' + geolocs_airbnb.latitude.str[2:]).astype(float)\n\n#print(type(geolocs_airbnb.latitude[5]))\n\n#print(longitude)\n#print(geolocs_airbnb)\n#print(len(geolocs_airbnb))\nfor i in range(len(geolocs_airbnb)):\n    latitude, longitude = geolocs_airbnb.iloc[i]['latitude'],geolocs_airbnb.iloc[i]['longitude']\n    print(f'{latitude}, {longitude}')\n    location = geolocator.reverse((latitude, longitude), timeout=None)\n    try:\n        street = location.raw['address']['road']\n        geolocs_airbnb.loc[i, 'street'] = street\n    except:\n        pass\n\ngeolocs_airbnb.head()\n\n#adding street as a column in our dataframe\ngeolocs_airbnb['street'] = street\n\nIndex(['ï»¿id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n       'host_neighbourhood', 'host_listings_count',\n       'host_total_listings_count', 'host_verifications',\n       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n       'maximum_minimum_nights', 'minimum_maximum_nights',\n       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n       'availability_30', 'availability_60', 'availability_90',\n       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n       'review_scores_cleanliness', 'review_scores_checkin',\n       'review_scores_communication', 'review_scores_location',\n       'review_scores_value', 'license', 'instant_bookable',\n       'calculated_host_listings_count',\n       'calculated_host_listings_count_entire_homes',\n       'calculated_host_listings_count_private_rooms',\n       'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n       'new_price'],\n      dtype='object')\n\n\nC:\\Users\\jjcor\\AppData\\Local\\Temp\\ipykernel_5424\\340548867.py:31: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nC:\\Users\\jjcor\\AppData\\Local\\Temp\\ipykernel_5424\\340548867.py:36: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\nValueError: could not convert string to float: '52..37'\n\n\n\n#print(geolocs_airbnb.street)\nprint('Number of Airbnb listings per street:', geolocs_airbnb.street.value_counts())\n\nAttributeError: 'DataFrame' object has no attribute 'street'\n\n\n\n\n4. Try to cross reference the data from the AirBnB dataset with the BBGA. Can you figure out if all apartments of AirBnB are designated as housing? Which number of apartments are not rented out all the time but are also used as normal housing?\nThe two datasets have no categories with immediate similar classification, therefore the cross reference of information is not possible.\n\n\n5. How many hotel rooms should be built if Amsterdam wants to accommodate the same number of tourists?\n\n#we sum individually the column 'accommodates' so we can retrieve the number of people who can stay \nno_ppl = ok_listings.accommodates.sum()\n\ntourists = 30000\n\ntourists_hotel = tourists-no_ppl\n\nhotel_rooms_ams = 41840\nhotel_beds_ams = 90918\n\navg_beds_per_room = hotel_beds_ams/hotel_rooms_ams\n\n#print(avg_beds_per_room)\n\n#Number of hotel rooms used by tourists who don't fit in airbnbs\nno_hotel_rooms_used = tourists_hotel/avg_beds_per_room\n\nprint('Number of hotel rooms used by tourists who do not fit in airbnbs:', no_hotel_rooms_used)\n\nNameError: name 'ok_listings' is not defined\n\n\n\n\n6. How many different licenses are issued?\n\n#verifying license column\n#print(ok_listings.columns[68])\nlicenses = (ok_listings.license.nunique())\nlicense_values =(ok_listings.license.value_counts())\nprint(license_values)\nexemptions = (ok_listings.license.value_counts()['Exempt'])\n\nulicenses = licenses-exemptions\nprint('Number of unique Airbnb licenses in Amsterdam (not counting the exempt values):',ulicenses)\n\nlicense\nExempt                      600\n0363 78AD 8875 790E 3C05     14\nABCD 1234 AB12 89EF A0F9      9\n036341086EC3C2FF2493          7\n0363 A250 F710 53C5 1273      6\n                           ... \n0363 D239 E048 910F 216B      1\n0363 CB7E 060D 07E0 A4DE      1\n0363 45B2 6D92 AA8B 1326      1\n0363 F6A5 F87A D89D 8FC1      1\n0363 2F20 4F53 FB57 2D7F      1\nName: count, Length: 6972, dtype: int64\nNumber of unique Airbnb licenses in Amsterdam (not counting the exempt values): 6372\n\n\n\n\nResults analysis:\nWe have more listings than licenses and several ‘exempt’ values. This is because the listings already have another type of license since they either work as hotels or hostels. https://www.airbnb.com/help/article/860"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Amsterdam Open Water Swim Meet Report",
    "section": "",
    "text": "This is a report on the feasibility of hosting a 5km open water swimming event through the canals of Amsterdam, based on the theoretical concerns raised by the municipality of Amsterdam.\nKey facts\n\nWhat: The swim has to have a length of 5km.\nWhere: Has to be proposed anywhere in the canals of Amsterdam according to infromation gathered.\nWhen: May 2024\n\nContents of report\n\nFeasibility of event based on water quality\nEnergy requirements for event\nAccommodation tendencies from tourism\nEvent ammenities"
  }
]